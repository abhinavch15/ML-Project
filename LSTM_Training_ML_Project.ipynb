{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Training ML Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "85oYQ_u9gYFF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import string as str\r\n",
        "import regex as re\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "import pickle\r\n",
        "import keras\r\n",
        "import matplotlib\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Ws0Ncn5ighhU",
        "outputId": "9285fd30-e702-4ba8-93f2-549dc1498334"
      },
      "source": [
        "df = pd.read_csv('data.csv')\r\n",
        "df = df.drop(df.columns[0],axis=1)\r\n",
        "df = df.dropna()\r\n",
        "df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77212</th>\n",
              "      <td>vision of flames approaching corryong in victoria</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77213</th>\n",
              "      <td>wa police and government backflip on drug amne...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77214</th>\n",
              "      <td>we have fears for their safety: victorian premier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77215</th>\n",
              "      <td>when do the 20s start</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77216</th>\n",
              "      <td>yarraville shooting woman dead man critically ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77217 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  y\n",
              "0       Donald Trump Sends Out Embarrassing New Year’...  0\n",
              "1       Drunk Bragging Trump Staffer Started Russian ...  0\n",
              "2       Sheriff David Clarke Becomes An Internet Joke...  0\n",
              "3       Trump Is So Obsessed He Even Has Obama’s Name...  0\n",
              "4       Pope Francis Just Called Out Donald Trump Dur...  0\n",
              "...                                                  ... ..\n",
              "77212  vision of flames approaching corryong in victoria  1\n",
              "77213  wa police and government backflip on drug amne...  1\n",
              "77214  we have fears for their safety: victorian premier  1\n",
              "77215                              when do the 20s start  1\n",
              "77216  yarraville shooting woman dead man critically ...  1\n",
              "\n",
              "[77217 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF8h_Qozw7Te",
        "outputId": "5796da55-6315-4d89-e8be-9de52e0b68d2"
      },
      "source": [
        "len(df[df['y']==0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mF4gXixRUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb29f93-72a9-41ba-de47-ddceab434488"
      },
      "source": [
        "len(df[df['y']==1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gq2PP0ng0Xu"
      },
      "source": [
        "def clean_doc(doc):\r\n",
        "\t# split into tokens by white space\r\n",
        "    \r\n",
        "    doc=doc.lower()\r\n",
        "    \r\n",
        "    doc = re.sub(r'[^\\w\\s]','',doc)\r\n",
        "    #remove digits\r\n",
        "    doc = re.sub(\"\\d+\",\"\",doc)\r\n",
        "    #remove excess whitespaces\r\n",
        "    doc = re.sub(\"\\s+\",\" \",doc)\r\n",
        "    \r\n",
        "    return doc.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzmjmChGvWfH"
      },
      "source": [
        "df['clean title'] = df['title'].apply(clean_doc)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb_fOG7Ay98C",
        "outputId": "c276d8ef-dc1a-48d7-9441-76370cc2a0f3"
      },
      "source": [
        "lens = []\r\n",
        "for s in df['clean title'].str.split():\r\n",
        "  lens.append(len(s))\r\n",
        "\r\n",
        "print(max(lens))\r\n",
        "\r\n",
        "#We will use this as max_seq_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXplsPJnhvo1"
      },
      "source": [
        "def fetch_word_vectors():\r\n",
        "    f = open('glove.6B.300d.txt',encoding = \"utf-8\")\r\n",
        "    embedd_index = {}\r\n",
        "    for line in f:\r\n",
        "        val = line.split()\r\n",
        "        word = val[0]\r\n",
        "        coff = np.asarray(val[1:],dtype = 'float')\r\n",
        "        embedd_index[word] = coff\r\n",
        "    f.close()\r\n",
        "    #print('Found %s word vectors.' % len(embedd_index))\r\n",
        "    return(embedd_index)\r\n",
        "  \r\n",
        "def construct_embedding(embedd_index,index_of_words,embed_num_dims):\r\n",
        "    embedding_matrix = np.zeros((len(index_of_words) + 1, embed_num_dims))\r\n",
        "    for word,i in index_of_words.items():\r\n",
        "        temp = embedd_index.get(word)\r\n",
        "        if temp is not None:\r\n",
        "            embedding_matrix[i] = temp\r\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srrSRFOorRvm"
      },
      "source": [
        "def tokenize_sentences(sentences,num_words,embed_num_dims,max_seq_len):\r\n",
        "    tokenizer = Tokenizer(num_words)\r\n",
        "    tokenizer.fit_on_texts(sentences)\r\n",
        "    sequence = tokenizer.texts_to_sequences(sentences)\r\n",
        "    index_of_words = tokenizer.word_index\r\n",
        "    padded_seq = pad_sequences(sequence, maxlen = max_seq_len)\r\n",
        "    return (tokenizer,index_of_words, padded_seq)\r\n",
        "\r\n",
        "def contruct_model(embedding_matrix,index_of_words,embed_num_dims,max_seq_len):\r\n",
        "    model = Sequential()\r\n",
        "    embedd_layer = Embedding(len(index_of_words) + 1 , embed_num_dims , input_length = max_seq_len , weights = [embedding_matrix])\r\n",
        "    model.add(embedd_layer)\r\n",
        "    model.add(SpatialDropout1D(0.4))\r\n",
        "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\r\n",
        "    model.add(Dense(2,activation='softmax'))\r\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\r\n",
        "    print(model.summary())\r\n",
        "    return model\r\n",
        "\r\n",
        "def train(model,X_train,Y_train):\r\n",
        "    es = EarlyStopping(monitor='loss', mode='min', verbose=1)\r\n",
        "    model.fit(X_train, Y_train, epochs = 20, batch_size=32, verbose = 2, callbacks=[es]) \r\n",
        "    \r\n",
        "def evaluate(model,X_test,Y_test):\r\n",
        "    score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = 32)\r\n",
        "    print(\"score: %.2f\" % (score))\r\n",
        "    print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirE_gzNrcht",
        "outputId": "e0fd00c3-0a7b-40f0-81f1-0ade265d6a47"
      },
      "source": [
        "embedd_index = fetch_word_vectors()\r\n",
        "\r\n",
        "tokenizer,index_of_words,padded_seq = tokenize_sentences(df['clean title'],num_words=100000,embed_num_dims=300,max_seq_len=67)\r\n",
        "    \r\n",
        "#construct embedding matrix\r\n",
        "embedding_matrix = construct_embedding(embedd_index,index_of_words,embed_num_dims=300)\r\n",
        "\r\n",
        "model = contruct_model(embedding_matrix,index_of_words,embed_num_dims=300,max_seq_len=67)\r\n",
        "Y = pd.get_dummies(df['y']).values\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(padded_seq,Y, test_size = 0.3, random_state = 42)\r\n",
        "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 67, 300)           12415500  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 67, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               389648    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 12,805,542\n",
            "Trainable params: 12,805,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(54051, 67) (54051, 2) (23166, 67) (23166, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqU1ZHgttODx",
        "outputId": "c3281e49-e4a6-47ab-f1f1-aa333c238f66"
      },
      "source": [
        "train(model,X_train,Y_train)\r\n",
        "#evaluate(model,X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1690/1690 - 568s - loss: 0.2503 - accuracy: 0.8936\n",
            "Epoch 2/20\n",
            "1690/1690 - 571s - loss: 0.1420 - accuracy: 0.9432\n",
            "Epoch 3/20\n",
            "1690/1690 - 578s - loss: 0.0948 - accuracy: 0.9629\n",
            "Epoch 4/20\n",
            "1690/1690 - 560s - loss: 0.0644 - accuracy: 0.9760\n",
            "Epoch 5/20\n",
            "1690/1690 - 557s - loss: 0.0436 - accuracy: 0.9838\n",
            "Epoch 6/20\n",
            "1690/1690 - 566s - loss: 0.0308 - accuracy: 0.9885\n",
            "Epoch 7/20\n",
            "1690/1690 - 551s - loss: 0.0219 - accuracy: 0.9922\n",
            "Epoch 8/20\n",
            "1690/1690 - 553s - loss: 0.0163 - accuracy: 0.9943\n",
            "Epoch 9/20\n",
            "1690/1690 - 556s - loss: 0.0122 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1690/1690 - 567s - loss: 0.0096 - accuracy: 0.9967\n",
            "Epoch 11/20\n",
            "1690/1690 - 556s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 12/20\n",
            "1690/1690 - 553s - loss: 0.0066 - accuracy: 0.9976\n",
            "Epoch 13/20\n",
            "1690/1690 - 551s - loss: 0.0064 - accuracy: 0.9977\n",
            "Epoch 14/20\n",
            "1690/1690 - 554s - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 15/20\n",
            "1690/1690 - 554s - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 16/20\n",
            "1690/1690 - 541s - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P3uFlbkC7QB",
        "outputId": "82e472b3-4fb6-4846-9acc-5a5b383e9a46"
      },
      "source": [
        "evaluate(model,X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "724/724 - 11s - loss: 0.4876 - accuracy: 0.9346\n",
            "score: 0.49\n",
            "acc: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJoBtNsFS_Bi"
      },
      "source": [
        "def save_model_to_disk(model,model_name):\r\n",
        "    # serialize model to JSON\r\n",
        "    model_json = model.to_json()\r\n",
        "    with open(model_name+\".json\", \"w\") as json_file:\r\n",
        "        json_file.write(model_json)\r\n",
        "    # serialize weights to HDF5\r\n",
        "    model.save_weights(model_name+\".h5\")\r\n",
        "    #create pickle to save tokenizer\r\n",
        "    with open(model_name+\".pickle\", 'wb') as handle:\r\n",
        "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "    print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR_73MO2VA1W",
        "outputId": "43780ba1-0150-4110-ffe9-7db4fc28a209"
      },
      "source": [
        "model.save('lstm_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: lstm_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_WePSlXVk_C",
        "outputId": "db272cea-8cce-454f-cb6d-af9f8fb8ce6d"
      },
      "source": [
        "!zip -r /content/file.zip /content/lstm_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/lstm_model/ (stored 0%)\n",
            "  adding: content/lstm_model/variables/ (stored 0%)\n",
            "  adding: content/lstm_model/variables/variables.data-00000-of-00001 (deflated 27%)\n",
            "  adding: content/lstm_model/variables/variables.index (deflated 60%)\n",
            "  adding: content/lstm_model/saved_model.pb (deflated 89%)\n",
            "  adding: content/lstm_model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZ24JsEi9U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee15049e-9466-4377-ea75-563936e2bf69"
      },
      "source": [
        "save_model_to_disk(model,\"lstm_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2O4AW96YR7p",
        "outputId": "e1f16c50-521f-48ea-f395-da56dd166e2e"
      },
      "source": [
        "model = keras.models.load_model('lstm_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhTKuDStYwtF"
      },
      "source": [
        "def predict(text):\r\n",
        "    text = tokenizer.texts_to_sequences(text)\r\n",
        "    #padding the text to have exactly the same shape as embedding\r\n",
        "    text = pad_sequences(text, maxlen=67, dtype='int32', value=0)\r\n",
        "    y = model.predict(text,batch_size=1,verbose = 2)[0]\r\n",
        "    if(np.argmax(7) == 0):\r\n",
        "        print(\"Fake\")\r\n",
        "        return 0\r\n",
        "    elif (np.argmax(y) == 1):\r\n",
        "        print(\"True\")\r\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8UcENOAZbTd",
        "outputId": "ed9550b8-f8df-46b0-d5dd-582cb4181d9b"
      },
      "source": [
        "predict(\"Hubble Finds Exoplanet That Could Mirror Planet Nine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 - 0s\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}